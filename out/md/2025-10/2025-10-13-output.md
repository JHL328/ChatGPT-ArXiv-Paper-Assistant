# Personalized Daily ArXiv Papers 2025-10-13

| *[gpt-5]*   | Prompt   | Completion   | Total   |
|:-----------:|:--------:|:------------:|:-------:|
| **Token**   | 70602    | 59514        | 130116  |
| **Cost**    | $0.09    | $0.6         | $0.68   |

Total arXiv papers: 664

Total scanned papers: 395

Total relevant papers: 38

**Table of contents with paper titles:**

1. [LOTION: Smoothing the Optimization Landscape for Quantized Training](#user-content-link1)
**Authors:** Mujin Kwun, Depen Morwani, Chloe Huangyuan Su, Stephanie Gil, Nikhil Anand, Sham Kakade

2. [Neptune: Advanced ML Operator Fusion for Locality and Parallelism on GPUs](#user-content-link2)
**Authors:** Yifan Zhao, Egan Johnson, Prasanth Chatarasi, Vikram Adve, Sasa Misailovic

3. [Design Principles for Sequence Models via Coefficient Dynamics](#user-content-link3)
**Authors:** Jerome Sieber, Antonio Orvieto, Melanie N. Zeilinger, Carmen Amo Alonso

4. [Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers](#user-content-link4)
**Authors:** Rui Bu, Haofeng Zhong, Wenzheng Chen, Yangyan Li

5. [Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry](#user-content-link5)
**Authors:** Thomas Fel, Binxu Wang, Michael A. Lepori, Matthew Kowal, Andrew Lee, Randall Balestriero, Sonia Joseph, Ekdeep S. Lubana, Talia Konkle, Demba Ba, Martin Wattenberg

6. [PHyCLIP: $\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning](#user-content-link6)
**Authors:** Daiki Yoshikawa, Takashi Matsubara

7. [Conditional Flow Matching for Bayesian Posterior Inference](#user-content-link7)
**Authors:** So Won Jeong, Percy S. Zhai, Veronika Ro\v{c}ov\'a

8. [Transmuting prompts into weights](#user-content-link8)
**Authors:** Hanna Mazzawi, Benoit Dherin, Michael Munn, Michael Wunder, Javier Gonzalvo

9. [RepDL: Bit-level Reproducible Deep Learning Training and Inference](#user-content-link9)
**Authors:** Peichen Xie, Xian Zhang, Shuo Chen

10. [Upfront Chain-of-Thought: A Cooperative Framework for Chain-of-Thought Compression](#user-content-link10)
**Authors:** Chengzhengxu Li, Xiaoming Liu, Zhaohan Zhang, Shaochu Zhang, Shengchao Liu, Guoxin Ma, Yu Lan, Chao Shen

11. [AdaPM: a Partial Momentum Algorithm for LLM Training](#user-content-link11)
**Authors:** Yimu Zhang, Yuanshi Liu, Cong Fang

12. [StreamingVLM: Real-Time Understanding for Infinite Video Streams](#user-content-link12)
**Authors:** Ruyi Xu, Guangxuan Xiao, Yukang Chen, Liuning He, Kelly Peng, Yao Lu, Song Han

13. [Efficient Autoregressive Inference for Transformer Probabilistic Models](#user-content-link13)
**Authors:** Conor Hassan, Nasrulloh Loka, Cen-You Li, Daolang Huang, Paul E. Chang, Yang Yang, Francesco Silvestrin, Samuel Kaski, Luigi Acerbi

14. [Slicing Is All You Need: Towards A Universal One-Sided Algorithm for Distributed Matrix Multiplication](#user-content-link14)
**Authors:** Benjamin Brock, Renato Golin

15. [On the Alignment Between Supervised and Self-Supervised Contrastive Learning](#user-content-link15)
**Authors:** Achleshwar Luthra, Priyadarsi Mishra, Tomer Galanti

16. [On the Representations of Entities in Auto-regressive Large Language Models](#user-content-link16)
**Authors:** Victor Morand, Josiane Mothe, Benjamin Piwowarski

17. [Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation](#user-content-link17)
**Authors:** Devleena Das, Rajeev Patwari, Ashish Sirasao

18. [FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference](#user-content-link18)
**Authors:** Yu-Chen Lu, Chong-Yan Chen, Chi-Chih Chang, Yu-Fang Hu, Kai-Chiang Wu

19. [MODE: Learning compositional representations of complex systems with Mixtures Of Dynamical Experts](#user-content-link19)
**Authors:** Nathan Quiblier, Roy Friedman, Matthew Ricci

20. [Time-Aware Feature Selection: Adaptive Temporal Masking for Stable Sparse Autoencoder Training](#user-content-link20)
**Authors:** T. Ed Li, Junyu Ren

21. [Efficient Resource-Constrained Training of Vision Transformers via Subspace Optimization](#user-content-link21)
**Authors:** Le-Trung Nguyen, Enzo Tartaglione, Van-Tam Nguyen

22. [SQS: Bayesian DNN Compression through Sparse Quantized Sub-distributions](#user-content-link22)
**Authors:** Ziyi Wang, Nan Jiang, Guang Lin, Qifan Song

23. [Localist LLMs -- A Mathematical Framework for Dynamic Locality Control](#user-content-link23)
**Authors:** Joachim Diederich

24. [Task-Level Insights from Eigenvalues across Sequence Models](#user-content-link24)
**Authors:** Rahel Rickenbach, Jelena Trisovic, Alexandre Didier, Jerome Sieber, Melanie N. Zeilinger

25. [dInfer: An Efficient Inference Framework for Diffusion Language Models](#user-content-link25)
**Authors:** Yuxin Ma, Lun Du, Lanning Wei, Kun Chen, Qian Xu, Kangyu Wang, Guofeng Feng, Guoshan Lu, Lin Liu, Xiaojing Qi, Xinyuan Zhang, Zhen Tao, Haibo Feng, Ziyun Jiang, Ying Xu, Zenan Huang, Yihong Zhuang, Haokai Xu, Jiaqi Hu, Zhenzhong Lan, Junbo Zhao, Jianguo Li, Da Zheng

26. [Energy-Driven Steering: Reducing False Refusals in Large Language Models](#user-content-link26)
**Authors:** Eric Hanchen Jiang, Weixuan Ou, Run Liu, Shengyuan Pang, Guancheng Wan, Ranjie Duan, Wei Dong, Kai-Wei Chang, XiaoFeng Wang, Ying Nian Wu, Xinfeng Li

27. [On Uniformly Scaling Flows: A Density-Aligned Approach to Deep One-Class Classification](#user-content-link27)
**Authors:** Faried Abu Zaid, Tim Katzke, Emmanuel M\"uller, Daniel Neider

28. [On the Implicit Adversariality of Catastrophic Forgetting in Deep Continual Learning](#user-content-link28)
**Authors:** Ze Peng, Jian Zhang, Jintao Guo, Lei Qi, Yang Gao, Yinghuan Shi

29. [Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting](#user-content-link29)
**Authors:** Suming Qiu, Jing Li, Zhicheng Zhou, Junjie Huang, Linyuan Qiu, Zhijie Sun

30. [Verifying Chain-of-Thought Reasoning via Its Computational Graph](#user-content-link30)
**Authors:** Zheng Zhao, Yeskendir Koishekenov, Xianjun Yang, Naila Murray, Nicola Cancedda

31. [Toward Mechanistic Explanation of Deductive Reasoning in Language Models](#user-content-link31)
**Authors:** Davide Maltoni, Matteo Ferrara

32. [Training Feature Attribution for Vision Models](#user-content-link32)
**Authors:** Aziz Bacha, Thomas George

33. [The Potential of Second-Order Optimization for LLMs: A Study with Full Gauss-Newton](#user-content-link33)
**Authors:** Natalie Abreu, Nikhil Vyas, Sham Kakade, Depen Morwani

34. [Inverse-Free Wilson Loops for Transformers: A Practical Diagnostic for Invariance and Order Sensitivity](#user-content-link34)
**Authors:** Edward Y. Chang, Ethan Y. Chang

35. [QuIRK: Quantum-Inspired Re-uploading KAN](#user-content-link35)
**Authors:** Vinayak Sharma, Ashish Padhy, Vijay Jagdish Karanjkar, Sourav Behera, Lord Sen, Shyamapada Mukherjee, Aviral Shrivastava

36. [FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching](#user-content-link36)
**Authors:** Jiacheng Liu, Peiliang Cai, Qinming Zhou, Yuqi Lin, Deyang Kong, Benhao Huang, Yupei Pan, Haowen Xu, Chang Zou, Junshu Tang, Shikang Zheng, Linfeng Zhang

37. [Geodesic Calculus on Latent Spaces](#user-content-link37)
**Authors:** Florine Hartwig, Josua Sassen, Juliane Braunsmann, Martin Rumpf, Benedikt Wirth

38. [AB-PINNs: Adaptive-Basis Physics-Informed Neural Networks for Residual-Driven Domain Decomposition](#user-content-link38)
**Authors:** Jonah Botvinick-Greenhouse, Wael H. Ali, Mouhacine Benosman, Saviz Mowlavi

---

## 1. [LOTION: Smoothing the Optimization Landscape for Quantized Training](https://arxiv.org/abs/2510.08757) <a id="link1"></a>

**ArXiv ID:** 2510.08757

**Authors:** Mujin Kwun, Depen Morwani, Chloe Huangyuan Su, Stephanie Gil, Nikhil Anand, Sham Kakade

**Abstract:** Optimizing neural networks for quantized objectives is fundamentally challenging because the quantizer is piece-wise constant, yielding zero gradients everywhere except at quantization thresholds where the derivative is undefined. Most existing methods deal with this issue by relaxing gradient computations with techniques like Straight Through Estimators (STE) and do not provide any guarantees of convergence. In this work, taking inspiration from Nesterov smoothing, we approximate the quantized loss surface with a continuous loss surface. In particular, we introduce LOTION, \textbf{L}ow-precision \textbf{O}ptimization via s\textbf{T}ochastic-no\textbf{I}se sm\textbf{O}othi\textbf{N}g, a principled smoothing framework that replaces the raw quantized loss with its expectation under unbiased randomized-rounding noise. In this framework, standard optimizers are guaranteed to converge to a local minimum of the loss surface. Moreover, when using noise derived from stochastic rounding, we show that the global minima of the original quantized loss are preserved. We empirically demonstrate that this method outperforms standard QAT on synthetic testbeds and on 150M- and 300M- parameter language models.

**Comment:** Model Compression and Efficiency: introduces a principled smoothing framework for quantized training with convergence guarantees and preservation of quantized minima.

**Relevance:** 10
**Novelty:** 9

---

## 2. [Neptune: Advanced ML Operator Fusion for Locality and Parallelism on GPUs](https://arxiv.org/abs/2510.08726) <a id="link2"></a>

**ArXiv ID:** 2510.08726

**Authors:** Yifan Zhao, Egan Johnson, Prasanth Chatarasi, Vikram Adve, Sasa Misailovic

**Abstract:** Operator fusion has become a key optimization for deep learning, which combines multiple deep learning operators to improve data reuse and reduce global memory transfers. However, existing tensor compilers struggle to fuse complex reduction computations involving loop-carried dependencies, such as attention mechanisms.   The paper introduces Neptune, a tensor compiler for advanced operator fusion for sequences of reduction operators. Neptune presents a new approach for advanced operator fusion, which intentionally breaks some existing dependencies and compensates by constructing algebraic correction expressions that allow the kernel to produce the correct result.   On ten attention-based benchmarks, Neptune, starting from simple attention code and a high-level scheduling template, outperforms existing compilers like Triton, TVM, and FlexAttention, including Triton-based implementations of FlashAttention. Across four different GPU architectures from NVIDIA and AMD, Neptune-generated kernels have average speedup of $1.35\times$ over the next best alternative, demonstrating its effectiveness for deep learning workloads.

**Comment:** Matches ML Systems (compiler/operator fusion): new fusion scheme for reduction-heavy kernels (attention) with algebraic correction; kernel-level speedups across GPUs.

**Relevance:** 10
**Novelty:** 9

---

## 3. [Design Principles for Sequence Models via Coefficient Dynamics](https://arxiv.org/abs/2510.09389) <a id="link3"></a>

**ArXiv ID:** 2510.09389

**Authors:** Jerome Sieber, Antonio Orvieto, Melanie N. Zeilinger, Carmen Amo Alonso

**Abstract:** Deep sequence models, ranging from Transformers and State Space Models (SSMs) to more recent approaches such as gated linear RNNs, fundamentally compute outputs as linear combinations of past value vectors. To draw insights and systematically compare such architectures, we develop a unified framework that makes this output operation explicit, by casting the linear combination coefficients as the outputs of autonomous linear dynamical systems driven by impulse inputs. This viewpoint, in spirit substantially different from approaches focusing on connecting linear RNNs with linear attention, reveals a common mathematical theme across diverse architectures and crucially captures softmax attention, on top of RNNs, SSMs, and related models. In contrast to new model proposals that are commonly evaluated on benchmarks, we derive design principles linking architectural choices to model properties. Thereby identifying tradeoffs between expressivity and efficient implementation, geometric constraints on input selectivity, and stability conditions for numerically stable training and information retention. By connecting several insights and observations from recent literature, the framework both explains empirical successes of recent designs and provides guiding principles for systematically designing new sequence model architectures.

**Comment:** Matches Model Architecture and Representation Learning: unifies Transformers/SSMs/linear RNNs via autonomous linear dynamical systems for coefficient dynamics; derives design principles (stability, expressivity–efficiency).

**Relevance:** 10
**Novelty:** 8

---

## 4. [Value-State Gated Attention for Mitigating Extreme-Token Phenomena in Transformers](https://arxiv.org/abs/2510.09017) <a id="link4"></a>

**ArXiv ID:** 2510.09017

**Authors:** Rui Bu, Haofeng Zhong, Wenzheng Chen, Yangyan Li

**Abstract:** Large models based on the Transformer architecture are susceptible to extreme-token phenomena, such as attention sinks and value-state drains. These issues, which degrade model performance, quantization fidelity, and interpretability, arise from a problematic mutual reinforcement mechanism where the model learns an inefficient 'no-op' behavior by focusing attention on tokens with near-zero value states. In this paper, we propose Value-State Gated Attention (VGA), a simple, dedicated, and stable architectural mechanism for performing 'no-op' attention efficiently by directly breaking this cycle. VGA introduces a learnable, data-dependent gate, computed directly from the value vectors (V), to modulate the output. Through a theoretical analysis of the underlying gradients, we show that gating the value-state with a function of itself is more effective at decoupling value and attention score updates than prior methods that gate on input embeddings. This creates a direct regulatory pathway that allows the model to suppress a token's contribution based on its emergent value representation. Our experiments demonstrate that VGA significantly mitigates the formation of attention sinks and stabilizes value-state norms, leading to improved performance, robust quantization fidelity, and enhanced model interpretability.

**Comment:** Model Architecture: introduces Value-State Gated Attention to address extreme-token phenomena in Transformers with theoretical gradient analysis; also benefits quantization stability.

**Relevance:** 10
**Novelty:** 8

---

## 5. [Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry](https://arxiv.org/abs/2510.08638) <a id="link5"></a>

**ArXiv ID:** 2510.08638

**Authors:** Thomas Fel, Binxu Wang, Michael A. Lepori, Matthew Kowal, Andrew Lee, Randall Balestriero, Sonia Joseph, Ekdeep S. Lubana, Talia Konkle, Demba Ba, Martin Wattenberg

**Abstract:** DINOv2 is routinely deployed to recognize objects, scenes, and actions; yet the nature of what it perceives remains unknown. As a working baseline, we adopt the Linear Representation Hypothesis (LRH) and operationalize it using SAEs, producing a 32,000-unit dictionary that serves as the interpretability backbone of our study, which unfolds in three parts.   In the first part, we analyze how different downstream tasks recruit concepts from our learned dictionary, revealing functional specialization: classification exploits "Elsewhere" concepts that fire everywhere except on target objects, implementing learned negations; segmentation relies on boundary detectors forming coherent subspaces; depth estimation draws on three distinct monocular depth cues matching visual neuroscience principles.   Following these functional results, we analyze the geometry and statistics of the concepts learned by the SAE. We found that representations are partly dense rather than strictly sparse. The dictionary evolves toward greater coherence and departs from maximally orthogonal ideals (Grassmannian frames). Within an image, tokens occupy a low dimensional, locally connected set persisting after removing position. These signs suggest representations are organized beyond linear sparsity alone.   Synthesizing these observations, we propose a refined view: tokens are formed by combining convex mixtures of archetypes (e.g., a rabbit among animals, brown among colors, fluffy among textures). This structure is grounded in Gardenfors' conceptual spaces and in the model's mechanism as multi-head attention produces sums of convex mixtures, defining regions bounded by archetypes. We introduce the Minkowski Representation Hypothesis (MRH) and examine its empirical signatures and implications for interpreting vision-transformer representations.

**Comment:** Representation Learning: analyzes ViT internal concepts with SAEs and proposes the Minkowski Representation Hypothesis, giving geometric/structural insight into how tokens encode concepts.

**Relevance:** 9
**Novelty:** 8

---

## 6. [PHyCLIP: $\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning](https://arxiv.org/abs/2510.08919) <a id="link6"></a>

**ArXiv ID:** 2510.08919

**Authors:** Daiki Yoshikawa, Takashi Matsubara

**Abstract:** Vision-language models have achieved remarkable success in multi-modal representation learning from large-scale pairs of visual scenes and linguistic descriptions. However, they still struggle to simultaneously express two distinct types of semantic structures: the hierarchy within a concept family (e.g., dog $\preceq$ mammal $\preceq$ animal) and the compositionality across different concept families (e.g., "a dog in a car" $\preceq$ dog, car). Recent works have addressed this challenge by employing hyperbolic space, which efficiently captures tree-like hierarchy, yet its suitability for representing compositionality remains unclear. To resolve this dilemma, we propose PHyCLIP, which employs an $\ell_1$-Product metric on a Cartesian product of Hyperbolic factors. With our design, intra-family hierarchies emerge within individual hyperbolic factors, and cross-family composition is captured by the $\ell_1$-product metric, analogous to a Boolean algebra. Experiments on zero-shot classification, retrieval, hierarchical classification, and compositional understanding tasks demonstrate that PHyCLIP outperforms existing single-space approaches and offers more interpretable structures in the embedding space.

**Comment:** Representation Learning: proposes an ℓ1-product of hyperbolic factors for embeddings to unify hierarchy and compositionality, offering a new geometric representation design.

**Relevance:** 9
**Novelty:** 8

---

## 7. [Conditional Flow Matching for Bayesian Posterior Inference](https://arxiv.org/abs/2510.09534) <a id="link7"></a>

**ArXiv ID:** 2510.09534

**Authors:** So Won Jeong, Percy S. Zhai, Veronika Ro\v{c}ov\'a

**Abstract:** We propose a generative multivariate posterior sampler via flow matching. It offers a simple training objective, and does not require access to likelihood evaluation. The method learns a dynamic, block-triangular velocity field in the joint space of data and parameters, which results in a deterministic transport map from a source distribution to the desired posterior. The inverse map, named vector rank, is accessible by reversibly integrating the velocity over time. It is advantageous to leverage the dynamic design: proper constraints on the velocity yield a monotone map, which leads to a conditional Brenier map, enabling a fast and simultaneous generation of Bayesian credible sets whose contours correspond to level sets of Monge-Kantorovich data depth. Our approach is computationally lighter compared to GAN-based and diffusion-based counterparts, and is capable of capturing complex posterior structures. Finally, frequentist theoretical guarantee on the consistency of the recovered posterior distribution, and of the corresponding Bayesian credible sets, is provided.

**Comment:** Matches Model Architecture/Representation Learning criteria: introduces conditional flow matching with a block-triangular velocity field to learn monotone transport maps (conditional Brenier map) for posterior inference with theoretical guarantees.

**Relevance:** 9
**Novelty:** 8

---

## 8. [Transmuting prompts into weights](https://arxiv.org/abs/2510.08734) <a id="link8"></a>

**ArXiv ID:** 2510.08734

**Authors:** Hanna Mazzawi, Benoit Dherin, Michael Munn, Michael Wunder, Javier Gonzalvo

**Abstract:** A growing body of research has demonstrated that the behavior of large language models can be effectively controlled at inference time by directly modifying their internal states, either through vector additions to their activations or through updates to their weight matrices. These techniques, while powerful, are often guided by empirical heuristics, such as deriving steering vectors from the average activations of contrastive prompts. This work provides a theoretical foundation for these interventions, explaining how they emerge from the fundamental computations of the transformer architecture. Building on the recent finding that a prompt's influence can be mathematically mapped to implicit weight updates (Dherin et al., 2025), we generalize this theory to deep, multi-block transformers. We show how the information contained in any chunk of a user prompt is represented and composed internally through weight vectors and weight matrices. We then derive a principled method for condensing this information into token-independent thought vectors and thought matrices. These constructs provide a theoretical explanation for existing vector- and matrix-based model editing techniques and offer a direct, computationally-grounded method for transmuting textual input into reusable weight updates.

**Comment:** Model Architecture/Analysis: formal mapping from prompts to implicit weight updates in deep Transformers; introduces token-independent thought vectors/matrices for principled model editing.

**Relevance:** 9
**Novelty:** 8

---

## 9. [RepDL: Bit-level Reproducible Deep Learning Training and Inference](https://arxiv.org/abs/2510.09180) <a id="link9"></a>

**ArXiv ID:** 2510.09180

**Authors:** Peichen Xie, Xian Zhang, Shuo Chen

**Abstract:** Non-determinism and non-reproducibility present significant challenges in deep learning, leading to inconsistent results across runs and platforms. These issues stem from two origins: random number generation and floating-point computation. While randomness can be controlled through deterministic configurations, floating-point inconsistencies remain largely unresolved. To address this, we introduce RepDL, an open-source library that ensures deterministic and bitwise-reproducible deep learning training and inference across diverse computing environments. RepDL achieves this by enforcing correct rounding and order invariance in floating-point computation. The source code is available at https://github.com/microsoft/RepDL .

**Comment:** ML Systems: bitwise-reproducible training/inference via correct rounding and order-invariant floating-point computation; open-source library enabling generalizable deterministic execution.

**Relevance:** 9
**Novelty:** 8

---

## 10. [Upfront Chain-of-Thought: A Cooperative Framework for Chain-of-Thought Compression](https://arxiv.org/abs/2510.08647) <a id="link10"></a>

**ArXiv ID:** 2510.08647

**Authors:** Chengzhengxu Li, Xiaoming Liu, Zhaohan Zhang, Shaochu Zhang, Shengchao Liu, Guoxin Ma, Yu Lan, Chao Shen

**Abstract:** Recent developments have enabled advanced reasoning in Large Language Models (LLMs) via long Chain-of-Thought (CoT), while long CoT suffers from high computational costs and significant latency losses owing to the autoregressive nature of generative LLMs. CoT compression aims to improve efficiency in the reasoning process by reducing output length. Previous works trade reasoning efficiency by either laborious discrete prompt designing or the construction of external compressed CoT datasets that sacrifice key reasoning details. In this work, we propose Upfront CoT (UCoT): an efficient reasoning framework with upfront thought embedding to automate CoT compression. UCoT is a cooperative workflow involving a small model (compressor) and a large model (executor). The first stage of UCoT trains compressor to generate upfront thought embeddings rich in reasoning information for the executor, avoiding the drawbacks of manually designed prompts. The second stage optimizes executor to utilize upfront thought embeddings to derive the correct answer with short reasoning, using a reward mechanism. Extensive experiments show that UCoT maintains the powerful reasoning ability of executor while significantly reducing the length of CoT. It is worth mentioning that when applying UCoT to the Qwen2.5-7B-Instruct model, the usage of tokens on GSM8K dataset is reduced by 50\%, while the performance is 3.08\% higher than that of the state-of-the-art (SOTA) method. The code and dataset are in supplementary material.

**Comment:** Compression/Efficiency: Chain-of-Thought compression via upfront thought embeddings with a small compressor and large executor, reducing token usage while preserving reasoning.

**Relevance:** 9
**Novelty:** 8

---

## 11. [AdaPM: a Partial Momentum Algorithm for LLM Training](https://arxiv.org/abs/2510.09103) <a id="link11"></a>

**ArXiv ID:** 2510.09103

**Authors:** Yimu Zhang, Yuanshi Liu, Cong Fang

**Abstract:** In the training of large language models, momentum is widely used and often demonstrated to achieve significant acceleration. However, storing momentum typically presents memory challenges. In this paper, we propose AdaPM, an adaptive training strategy that leverages partial momentum to implement a memory-efficient optimizer. To this end, AdaPM utilizes a non-uniform momentum design: for most blocks, full momentum is not necessary to preserve the performance of the optimization. In the momentum design of AdaPM, to mitigate the bias and performance loss caused by partial momentum, we enhance the partial momentum by a bias correction technique. Empirically, we verify that our approach reduces memory by over $90\%$ in momentum while maintaining both efficiency and performance for pretraining various language models ranging from 60M to 1.5B, as well as for supervised fine-tuning and RLHF. AdaPM can further reduce memory by up to $95\%$ in optimizer states by combining the memory-efficient technique on the second-order statistic, saving over $30\%$ GPU hours for pretraining GPT-2 1.5B.

**Comment:** Matches ML Systems/Efficiency: memory-optimized optimizer via partial momentum with bias correction, drastically reducing optimizer state memory for LLM training.

**Relevance:** 9
**Novelty:** 8

---

## 12. [StreamingVLM: Real-Time Understanding for Infinite Video Streams](https://arxiv.org/abs/2510.09608) <a id="link12"></a>

**ArXiv ID:** 2510.09608

**Authors:** Ruyi Xu, Guangxuan Xiao, Yukang Chen, Liuning He, Kelly Peng, Yao Lu, Song Han

**Abstract:** Vision-language models (VLMs) could power real-time assistants and autonomous agents, but they face a critical challenge: understanding near-infinite video streams without escalating latency and memory usage. Processing entire videos with full attention leads to quadratic computational costs and poor performance on long videos. Meanwhile, simple sliding window methods are also flawed, as they either break coherence or suffer from high latency due to redundant recomputation. In this paper, we introduce StreamingVLM, a model designed for real-time, stable understanding of infinite visual input. Our approach is a unified framework that aligns training with streaming inference. During inference, we maintain a compact KV cache by reusing states of attention sinks, a short window of recent vision tokens, and a long window of recent text tokens. This streaming ability is instilled via a simple supervised fine-tuning (SFT) strategy that applies full attention on short, overlapped video chunks, which effectively mimics the inference-time attention pattern without training on prohibitively long contexts. For evaluation, we build Inf-Streams-Eval, a new benchmark with videos averaging over two hours that requires dense, per-second alignment between frames and text. On Inf-Streams-Eval, StreamingVLM achieves a 66.18% win rate against GPT-4O mini and maintains stable, real-time performance at up to 8 FPS on a single NVIDIA H100. Notably, our SFT strategy also enhances general VQA abilities without any VQA-specific fine-tuning, improving performance on LongVideoBench by +4.30 and OVOBench Realtime by +5.96. Code is available at https://github.com/mit-han-lab/streaming-vlm.

**Comment:** Matches ML Systems and Efficiency: streaming KV-cache design (attention-sink reuse, short/long windows) with SFT to align training–inference for low-latency, bounded-memory video understanding.

**Relevance:** 9
**Novelty:** 8

---

## 13. [Efficient Autoregressive Inference for Transformer Probabilistic Models](https://arxiv.org/abs/2510.09477) <a id="link13"></a>

**ArXiv ID:** 2510.09477

**Authors:** Conor Hassan, Nasrulloh Loka, Cen-You Li, Daolang Huang, Paul E. Chang, Yang Yang, Francesco Silvestrin, Samuel Kaski, Luigi Acerbi

**Abstract:** Transformer-based models for amortized probabilistic inference, such as neural processes, prior-fitted networks, and tabular foundation models, excel at single-pass marginal prediction. However, many real-world applications, from signal interpolation to multi-column tabular predictions, require coherent joint distributions that capture dependencies between predictions. While purely autoregressive architectures efficiently generate such distributions, they sacrifice the flexible set-conditioning that makes these models powerful for meta-learning. Conversely, the standard approach to obtain joint distributions from set-based models requires expensive re-encoding of the entire augmented conditioning set at each autoregressive step. We introduce a causal autoregressive buffer that preserves the advantages of both paradigms. Our approach decouples context encoding from updating the conditioning set. The model processes the context once and caches it. A dynamic buffer then captures target dependencies: as targets are incorporated, they enter the buffer and attend to both the cached context and previously buffered targets. This enables efficient batched autoregressive generation and one-pass joint log-likelihood evaluation. A unified training strategy allows seamless integration of set-based and autoregressive modes at minimal additional cost. Across synthetic functions, EEG signals, cognitive models, and tabular data, our method matches predictive accuracy of strong baselines while delivering up to 20 times faster joint sampling. Our approach combines the efficiency of autoregressive generative models with the representational power of set-based conditioning, making joint prediction practical for transformer-based probabilistic models.

**Comment:** Matches ML Systems and Model Architecture: causal autoregressive buffer decouples context encoding from target updates, enabling cached, batched joint inference with up to 20x faster sampling.

**Relevance:** 9
**Novelty:** 8

---

## 14. [Slicing Is All You Need: Towards A Universal One-Sided Algorithm for Distributed Matrix Multiplication](https://arxiv.org/abs/2510.08874) <a id="link14"></a>

**ArXiv ID:** 2510.08874

**Authors:** Benjamin Brock, Renato Golin

**Abstract:** Many important applications across science, data analytics, and AI workloads depend on distributed matrix multiplication. Prior work has developed a large array of algorithms suitable for different problem sizes and partitionings including 1D, 2D, 1.5D, and 2.5D algorithms. A limitation of current work is that existing algorithms are limited to a subset of partitionings. Multiple algorithm implementations are required to support the full space of possible partitionings. If no algorithm implementation is available for a particular set of partitionings, one or more operands must be redistributed, increasing communication costs. This paper presents a universal one-sided algorithm for distributed matrix multiplication that supports all combinations of partitionings and replication factors. Our algorithm uses slicing (index arithmetic) to compute the sets of overlapping tiles that must be multiplied together. This list of local matrix multiplies can then either be executed directly, or reordered and lowered to an optimized IR to maximize overlap. We implement our algorithm using a high-level C++-based PGAS programming framework that performs direct GPU-to-GPU communication using intra-node interconnects. We evaluate performance for a wide variety of partitionings and replication factors, finding that our work is competitive with PyTorch DTensor, a highly optimized distributed tensor library targeting AI models.

**Comment:** ML Systems/HPC: universal one-sided distributed matrix multiplication algorithm handling arbitrary partitionings/replication via slicing with GPU-to-GPU comms—generalizable systems-level contribution.

**Relevance:** 9
**Novelty:** 8

---

## 15. [On the Alignment Between Supervised and Self-Supervised Contrastive Learning](https://arxiv.org/abs/2510.08852) <a id="link15"></a>

**ArXiv ID:** 2510.08852

**Authors:** Achleshwar Luthra, Priyadarsi Mishra, Tomer Galanti

**Abstract:** Self-supervised contrastive learning (CL) has achieved remarkable empirical success, often producing representations that rival supervised pre-training on downstream tasks. Recent theory explains this by showing that the CL loss closely approximates a supervised surrogate, Negatives-Only Supervised Contrastive Learning (NSCL) loss, as the number of classes grows. Yet this loss-level similarity leaves an open question: {\em Do CL and NSCL also remain aligned at the representation level throughout training, not just in their objectives?}   We address this by analyzing the representation alignment of CL and NSCL models trained under shared randomness (same initialization, batches, and augmentations). First, we show that their induced representations remain similar: specifically, we prove that the similarity matrices of CL and NSCL stay close under realistic conditions. Our bounds provide high-probability guarantees on alignment metrics such as centered kernel alignment (CKA) and representational similarity analysis (RSA), and they clarify how alignment improves with more classes, higher temperatures, and its dependence on batch size. In contrast, we demonstrate that parameter-space coupling is inherently unstable: divergence between CL and NSCL weights can grow exponentially with training time.   Finally, we validate these predictions empirically, showing that CL-NSCL alignment strengthens with scale and temperature, and that NSCL tracks CL more closely than other supervised objectives. This positions NSCL as a principled bridge between self-supervised and supervised learning. Our code and project page are available at [\href{https://github.com/DLFundamentals/understanding_ssl_v2}{code}, \href{https://dlfundamentals.github.io/cl-nscl-representation-alignment/}{project page}].

**Comment:** Representation Learning — theoretical bounds on representation-level alignment between self-supervised and supervised contrastive learning (CKA/RSA).

**Relevance:** 9
**Novelty:** 8

---

## 16. [On the Representations of Entities in Auto-regressive Large Language Models](https://arxiv.org/abs/2510.09421) <a id="link16"></a>

**ArXiv ID:** 2510.09421

**Authors:** Victor Morand, Josiane Mothe, Benjamin Piwowarski

**Abstract:** Named entities are fundamental building blocks of knowledge in text, grounding factual information and structuring relationships within language. Despite their importance, it remains unclear how Large Language Models (LLMs) internally represent entities. Prior research has primarily examined explicit relationships, but little is known about entity representations themselves. We introduce entity mention reconstruction as a novel framework for studying how LLMs encode and manipulate entities. We investigate whether entity mentions can be generated from internal representations, how multi-token entities are encoded beyond last-token embeddings, and whether these representations capture relational knowledge. Our proposed method, leveraging _task vectors_, allows to consistently generate multi-token mentions from various entity representations derived from the LLMs hidden states. We thus introduce the _Entity Lens_, extending the _logit-lens_ to predict multi-token mentions. Our results bring new evidence that LLMs develop entity-specific mechanisms to represent and manipulate any multi-token entities, including those unseen during training. Our code is avalable at https://github.com/VictorMorand/EntityRepresentations .

**Comment:** Representation Learning: proposes Entity Lens (multi-token logit-lens) and task vectors to probe and reconstruct entity mentions from LLM hidden states.

**Relevance:** 9
**Novelty:** 7

---

## 17. [Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation](https://arxiv.org/abs/2510.08600) <a id="link17"></a>

**ArXiv ID:** 2510.08600

**Authors:** Devleena Das, Rajeev Patwari, Ashish Sirasao

**Abstract:** Inference optimizations such as quantization, pruning, format and datatype conversion, model export, and serialization can lead to functional degradations in language model task performance. While most efforts on performance recovery for deployment focus on robust quantization techniques, we focus on recovering model accuracies from any sources that degrade model weights, such as improper model serialization. In this work, we propose Recover-LoRA, a lightweight and dataset agnostic method to recover accuracy in degraded models. Recover-LoRA uses synthetic data and logit distillation to learn LoRA adapters on selective layers that facilitate aligning the degraded model to its full precision model. We investigate the utility of Recover-LoRA across a diverse set of small language models (SLMs), including models with varying attention architectures, multi-head attention (MHA) and group-query attention (GQA), as well as several evaluation datasets. Our results show that Recover-LoRA recovers model accuracies by 5-17% on MHA and GQA SLMs.

**Comment:** Compression/Efficiency: data-free accuracy recovery using low-rank adapters (LoRA) with logit distillation to realign degraded models post quantization/pruning/serialization.

**Relevance:** 9
**Novelty:** 7

---

## 18. [FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference](https://arxiv.org/abs/2510.09332) <a id="link18"></a>

**ArXiv ID:** 2510.09332

**Authors:** Yu-Chen Lu, Chong-Yan Chen, Chi-Chih Chang, Yu-Fang Hu, Kai-Chiang Wu

**Abstract:** Although large language models (LLM) have achieved remarkable performance, their enormous parameter counts hinder deployment on resource-constrained hardware. Low-rank compression can reduce both memory usage and computational demand, but applying a uniform compression ratio across all layers often leads to significant performance degradation, and previous methods perform poorly during decoding. To address these issues, we propose the Fine-grained Low-Rank Compressor (FLRC), which efficiently determines an optimal rank allocation for each layer, and incorporates progressive low-rank decoding to maintain text generation quality. Comprehensive experiments on diverse benchmarks demonstrate the superiority of FLRC, achieving up to a 17% improvement in ROUGE-L on summarization tasks compared to state-of-the-art low-rank compression methods, establishing a more robust and efficient framework to improve LLM inference.

**Comment:** Model Compression and Efficiency: fine-grained low-rank rank allocation per layer and progressive low-rank decoding for efficient LLM inference.

**Relevance:** 9
**Novelty:** 7

---

## 19. [MODE: Learning compositional representations of complex systems with Mixtures Of Dynamical Experts](https://arxiv.org/abs/2510.09594) <a id="link19"></a>

**ArXiv ID:** 2510.09594

**Authors:** Nathan Quiblier, Roy Friedman, Matthew Ricci

**Abstract:** Dynamical systems in the life sciences are often composed of complex mixtures of overlapping behavioral regimes. Cellular subpopulations may shift from cycling to equilibrium dynamics or branch towards different developmental fates. The transitions between these regimes can appear noisy and irregular, posing a serious challenge to traditional, flow-based modeling techniques which assume locally smooth dynamics. To address this challenge, we propose MODE (Mixture Of Dynamical Experts), a graphical modeling framework whose neural gating mechanism decomposes complex dynamics into sparse, interpretable components, enabling both the unsupervised discovery of behavioral regimes and accurate long-term forecasting across regime transitions. Crucially, because agents in our framework can jump to different governing laws, MODE is especially tailored to the aforementioned noisy transitions. We evaluate our method on a battery of synthetic and real datasets from computational biology. First, we systematically benchmark MODE on an unsupervised classification task using synthetic dynamical snapshot data, including in noisy, few-sample settings. Next, we show how MODE succeeds on challenging forecasting tasks which simulate key cycling and branching processes in cell biology. Finally, we deploy our method on human, single-cell RNA sequencing data and show that it can not only distinguish proliferation from differentiation dynamics but also predict when cells will commit to their ultimate fate, a key outstanding challenge in computational biology.

**Comment:** Model Architecture: Mixture Of Dynamical Experts with neural gating for sparse, interpretable decomposition of regimes—conditional/dynamic network design.

**Relevance:** 9
**Novelty:** 7

---

## 20. [Time-Aware Feature Selection: Adaptive Temporal Masking for Stable Sparse Autoencoder Training](https://arxiv.org/abs/2510.08855) <a id="link20"></a>

**ArXiv ID:** 2510.08855

**Authors:** T. Ed Li, Junyu Ren

**Abstract:** Understanding the internal representations of large language models is crucial for ensuring their reliability and safety, with sparse autoencoders (SAEs) emerging as a promising interpretability approach. However, current SAE training methods face feature absorption, where features (or neurons) are absorbed into each other to minimize $L_1$ penalty, making it difficult to consistently identify and analyze model behaviors. We introduce Adaptive Temporal Masking (ATM), a novel training approach that dynamically adjusts feature selection by tracking activation magnitudes, frequencies, and reconstruction contributions to compute importance scores that evolve over time. ATM applies a probabilistic masking mechanism based on statistical thresholding of these importance scores, creating a more natural feature selection process. Through extensive experiments on the Gemma-2-2b model, we demonstrate that ATM achieves substantially lower absorption scores compared to existing methods like TopK and JumpReLU SAEs, while maintaining excellent reconstruction quality. These results establish ATM as a principled solution for learning stable, interpretable features in neural networks, providing a foundation for more reliable model analysis.

**Comment:** Matches Representation Learning: innovations in sparse autoencoder training to stabilize features and reduce absorption.

**Relevance:** 9
**Novelty:** 7

---

## 21. [Efficient Resource-Constrained Training of Vision Transformers via Subspace Optimization](https://arxiv.org/abs/2510.09160) <a id="link21"></a>

**ArXiv ID:** 2510.09160

**Authors:** Le-Trung Nguyen, Enzo Tartaglione, Van-Tam Nguyen

**Abstract:** As AI increasingly shapes daily life, energy consumption and data privacy have become pressing concerns. On-device learning trains models directly on edge devices, cutting energy consumption and safeguarding data privacy. However, the expanding scale of modern neural networks creates a major obstacle for on-device training. Although prior work has concentrated on compact convolutional architectures, we instead apply subspace-based training to transformer models. Motivated by the idea that a model's essential information lies in a fixed subspace, we introduce Weight-Activation Subspace Iteration (WASI), a method that mitigates the memory bottleneck of backpropagation and boosts inference efficiency in transformer models by restricting training to this subspace. Our results demonstrate that WASI maintains accuracy comparable to vanilla training while reducing memory usage by up to $62\times$ and computational cost (FLOPs) by up to $2\times$. On a Raspberry Pi 5, WASI achieves roughly $1.5\times$ faster training and inference than vanilla training.

**Comment:** Matches Model Compression/Efficiency and ML Systems memory: subspace-constrained training for ViTs reducing memory/FLOPs for on-device learning.

**Relevance:** 9
**Novelty:** 7

---

## 22. [SQS: Bayesian DNN Compression through Sparse Quantized Sub-distributions](https://arxiv.org/abs/2510.08999) <a id="link22"></a>

**ArXiv ID:** 2510.08999

**Authors:** Ziyi Wang, Nan Jiang, Guang Lin, Qifan Song

**Abstract:** Compressing large-scale neural networks is essential for deploying models on resource-constrained devices. Most existing methods adopt weight pruning or low-bit quantization individually, often resulting in suboptimal compression rates to preserve acceptable performance drops. We introduce a unified framework for simultaneous pruning and low-bit quantization via Bayesian variational learning (SQS), which achieves higher compression rates than prior baselines while maintaining comparable performance. The key idea is to employ a spike-and-slab prior to inducing sparsity and model quantized weights using Gaussian Mixture Models (GMMs) to enable low-bit precision. In theory, we provide the consistent result of our proposed variational approach to a sparse and quantized deep neural network. Extensive experiments on compressing ResNet, BERT-base, Llama3, and Qwen2.5 models show that our method achieves higher compression rates than a line of existing methods with comparable performance drops.

**Comment:** Matches Model Compression/Efficiency: unified pruning+quantization via Bayesian variational learning (spike-and-slab + GMM), with theoretical consistency guarantees.

**Relevance:** 9
**Novelty:** 7

---

## 23. [Localist LLMs -- A Mathematical Framework for Dynamic Locality Control](https://arxiv.org/abs/2510.09338) <a id="link23"></a>

**ArXiv ID:** 2510.09338

**Authors:** Joachim Diederich

**Abstract:** We present a novel framework for training large language models with continuously adjustable internal representations that span the full spectrum from localist (interpretable, rule-based) to distributed (generalizable, efficient) encodings. The key innovation is a locality dial, a tunable parameter that dynamically controls the degree of localization during both training and inference without requiring model retraining. This is achieved through group sparsity penalties on attention mechanisms, information-theoretic anchor design, and dynamic rule injection. We provide rigorous mathematical proofs establishing explicit threshold conditions under which attention provably concentrates on semantically relevant blocks, with exponential bounds on attention entropy and pointer fidelity. Specifically, we prove that when group sparsity penalties exceed certain threshold values, the model's attention mechanisms concentrate on semantically relevant blocks, achieving low entropy and high fidelity with negligible error. This framework enables practitioners to continuously interpolate between interpretable and high-performance modes, supporting applications in regulated domains requiring both transparency and capability.

**Comment:** Matches Model Architecture/Representation: locality dial via group sparsity in attention with theoretical bounds, enabling dynamic control of interpretable vs distributed encodings.

**Relevance:** 9
**Novelty:** 7

---

## 24. [Task-Level Insights from Eigenvalues across Sequence Models](https://arxiv.org/abs/2510.09379) <a id="link24"></a>

**ArXiv ID:** 2510.09379

**Authors:** Rahel Rickenbach, Jelena Trisovic, Alexandre Didier, Jerome Sieber, Melanie N. Zeilinger

**Abstract:** Although softmax attention drives state-of-the-art performance for sequence models, its quadratic complexity limits scalability, motivating linear alternatives such as state space models (SSMs). While these alternatives improve efficiency, their fundamental differences in information processing remain poorly understood. In this work, we leverage the recently proposed dynamical systems framework to represent softmax, norm and linear attention as dynamical systems, enabling a structured comparison with SSMs by analyzing their respective eigenvalue spectra. Since eigenvalues capture essential aspects of dynamical system behavior, we conduct an extensive empirical analysis across diverse sequence models and benchmarks. We first show that eigenvalues influence essential aspects of memory and long-range dependency modeling, revealing spectral signatures that align with task requirements. Building on these insights, we then investigate how architectural modifications in sequence models impact both eigenvalue spectra and task performance. This correspondence further strengthens the position of eigenvalue analysis as a principled metric for interpreting, understanding, and ultimately improving the capabilities of sequence models.

**Comment:** Matches Representation Learning and Architecture Analysis: eigenvalue-spectrum analysis of attention and SSM sequence models to link memory/long-range dependency to task performance.

**Relevance:** 9
**Novelty:** 7

---

## 25. [dInfer: An Efficient Inference Framework for Diffusion Language Models](https://arxiv.org/abs/2510.08666) <a id="link25"></a>

**ArXiv ID:** 2510.08666

**Authors:** Yuxin Ma, Lun Du, Lanning Wei, Kun Chen, Qian Xu, Kangyu Wang, Guofeng Feng, Guoshan Lu, Lin Liu, Xiaojing Qi, Xinyuan Zhang, Zhen Tao, Haibo Feng, Ziyun Jiang, Ying Xu, Zenan Huang, Yihong Zhuang, Haokai Xu, Jiaqi Hu, Zhenzhong Lan, Junbo Zhao, Jianguo Li, Da Zheng

**Abstract:** Diffusion-based large language models (dLLMs) have emerged as a promising alternative to autoregressive (AR) LLMs, leveraging denoising-based generation to enable inherent parallelism. Even more and more open-sourced dLLM models emerge, yet their widespread adoption remains constrained by the lack of a standardized and efficient inference framework. We present dInfer, an efficient and extensible framework for dLLM inference. dInfer decomposes the inference pipeline into four modular components-model, diffusion iteration manager, decoding strategy, and KV-cache manager-and integrates novel algorithms for each component alongside system-level optimizations. Through this combination of algorithmic innovations and system enhancements, dInfer achieves substantial efficiency gains without compromising output quality on LLaDA-MoE. At batch size 1, it surpasses 1,100 tokens per second on HumanEval and averages over 800 tokens per second across six benchmarks on $8\times$ H800 GPUs. Compared to prior systems, dInfer delivers $10\times$ speedup over Fast-dLLM while maintaining similar model performance. Even compared with AR models (with a comparable number of activation parameters and performance) QWen2.5-3B, which is highly optimized with latest vLLM inference engine, dInfer still deliverers $2$-$3\times$ speedup. The implementation of dInfer is open-sourced at https://github.com/inclusionAI/dInfer.

**Comment:** ML Systems — algorithm–system co-design for dLLM inference (diffusion-iteration manager, decoding strategy, KV-cache manager) enabling high-throughput serving with open-source implementation.

**Relevance:** 9
**Novelty:** 7

---

## 26. [Energy-Driven Steering: Reducing False Refusals in Large Language Models](https://arxiv.org/abs/2510.08646) <a id="link26"></a>

**ArXiv ID:** 2510.08646

**Authors:** Eric Hanchen Jiang, Weixuan Ou, Run Liu, Shengyuan Pang, Guancheng Wan, Ranjie Duan, Wei Dong, Kai-Wei Chang, XiaoFeng Wang, Ying Nian Wu, Xinfeng Li

**Abstract:** Safety alignment of large language models (LLMs) faces a key challenge: current alignment techniques often only focus on improving safety against harmful prompts, causing LLMs to become over-cautious and refuse to respond to benign prompts. Therefore, a key objective of safe alignment is to enhance safety while simultaneously reducing false refusals. In this paper, we introduce Energy-Driven Steering (EDS), a novel, fine-tuning free framework designed to resolve this challenge through dynamic, inference-time intervention. We trained a lightweight, external Energy-Based Model (EBM) to assign high energy to undesirable (false refusal or jailbreak) states and low energy to desirable (helpful response or safe reject) ones. During inference, EBM maps the LLM's internal activations to an "energy landscape". We use the gradient of the energy function to dynamically steer the LLM's hidden states to low energy regions, correcting the model to generate a desirable response in real-time without modifying its weights. This method decouples behavioral control from the model's core knowledge, offering a flexible solution with minimal computational overhead. Extensive experiments across a wide range of models show our method successfully achieves this objective: it substantially lowers false refusal rates. For example, raising compliance on the ORB-H benchmark from 57.3% to 82.6% while maintaining the baseline safety performance. Our work presents an effective paradigm for building LLMs that achieve both low false refusal rates and high safety.

**Comment:** Matches Model Architecture criterion: proposes inference-time activation steering using a lightweight external EBM to dynamically modify hidden states without finetuning, a conditional/dynamic network control method.

**Relevance:** 8
**Novelty:** 8

---

## 27. [On Uniformly Scaling Flows: A Density-Aligned Approach to Deep One-Class Classification](https://arxiv.org/abs/2510.09452) <a id="link27"></a>

**ArXiv ID:** 2510.09452

**Authors:** Faried Abu Zaid, Tim Katzke, Emmanuel M\"uller, Daniel Neider

**Abstract:** Unsupervised anomaly detection is often framed around two widely studied paradigms. Deep one-class classification, exemplified by Deep SVDD, learns compact latent representations of normality, while density estimators realized by normalizing flows directly model the likelihood of nominal data. In this work, we show that uniformly scaling flows (USFs), normalizing flows with a constant Jacobian determinant, precisely connect these approaches. Specifically, we prove how training a USF via maximum-likelihood reduces to a Deep SVDD objective with a unique regularization that inherently prevents representational collapse. This theoretical bridge implies that USFs inherit both the density faithfulness of flows and the distance-based reasoning of one-class methods. We further demonstrate that USFs induce a tighter alignment between negative log-likelihood and latent norm than either Deep SVDD or non-USFs, and how recent hybrid approaches combining one-class objectives with VAEs can be naturally extended to USFs. Consequently, we advocate using USFs as a drop-in replacement for non-USFs in modern anomaly detection architectures. Empirically, this substitution yields consistent performance gains and substantially improved training stability across multiple benchmarks and model backbones for both image-level and pixel-level detection. These results unify two major anomaly detection paradigms, advancing both theoretical understanding and practical performance.

**Comment:** Matches Representation Learning/Theory: introduces uniformly scaling flows linking normalizing flows to Deep SVDD with regularization preventing collapse.

**Relevance:** 8
**Novelty:** 8

---

## 28. [On the Implicit Adversariality of Catastrophic Forgetting in Deep Continual Learning](https://arxiv.org/abs/2510.09181) <a id="link28"></a>

**ArXiv ID:** 2510.09181

**Authors:** Ze Peng, Jian Zhang, Jintao Guo, Lei Qi, Yang Gao, Yinghuan Shi

**Abstract:** Continual learning seeks the human-like ability to accumulate new skills in machine intelligence. Its central challenge is catastrophic forgetting, whose underlying cause has not been fully understood for deep networks. In this paper, we demystify catastrophic forgetting by revealing that the new-task training is implicitly an adversarial attack against the old-task knowledge. Specifically, the new-task gradients automatically and accurately align with the sharp directions of the old-task loss landscape, rapidly increasing the old-task loss. This adversarial alignment is intriguingly counter-intuitive because the sharp directions are too sparsely distributed to align with by chance. To understand it, we theoretically show that it arises from training's low-rank bias, which, through forward and backward propagation, confines the two directions into the same low-dimensional subspace, facilitating alignment. Gradient projection (GP) methods, a representative family of forgetting-mitigating methods, reduce adversarial alignment caused by forward propagation, but cannot address the alignment due to backward propagation. We propose backGP to address it, which reduces forgetting by 10.8% and improves accuracy by 12.7% on average over GP methods.

**Comment:** Representation Learning / Training Dynamics — theoretical link between forgetting and adversarial alignment via low-rank bias; proposes backGP to mitigate it.

**Relevance:** 8
**Novelty:** 8

---

## 29. [Logits Replay + MoClip: Stabilized, Low-Cost Post-Training with Minimal Forgetting](https://arxiv.org/abs/2510.09152) <a id="link29"></a>

**ArXiv ID:** 2510.09152

**Authors:** Suming Qiu, Jing Li, Zhicheng Zhou, Junjie Huang, Linyuan Qiu, Zhijie Sun

**Abstract:** Large language models (LLMs) often face a trade-off in post-training: improvements on specialized domains frequently come at the expense of general capabilities. Existing solutions attempt to mitigate this tension via regularization, selective parameter updates, or data-centric replay, but each imposes significant costs in computation, data access, or adaptability. Recent work has shown that training signals can be compressed to subsets of logits without severe accuracy loss, suggesting a path toward efficient adaptation. However, naive truncation destabilizes optimization and exacerbates forgetting.   We introduce Logits Replay + MoClip, a two-stage framework that compresses supervision in the logit space and stabilizes optimization at the update level. In Stage 0, we record dynamic Top-K token subsets that cover a probability threshold, always including the gold label. In Stage 1, we replay these compact subsets to compute exact renormalized losses, avoiding full softmax computation and implicitly regularizing. To ensure stability, we design MoClip, an optimizer that caps gradient-momentum rotation and applies an arctan2-based rescaling of updates. Empirically, our method improves domain performance on Communication Technology (CT) and NL2SQL tasks while mitigating forgetting on general benchmarks (MMLU, BBH, GPQA, MATH), and reduces training cost by over 40%. Together, these contributions offer a scalable, architecture-agnostic path for domain adaptation of LLMs without sacrificing generalization.

**Comment:** Model Compression and Efficiency: compresses supervision via dynamic Top-K logits replay with exact renormalized losses; optimizer-level stabilization (MoClip) reduces training cost.

**Relevance:** 8
**Novelty:** 7

---

## 30. [Verifying Chain-of-Thought Reasoning via Its Computational Graph](https://arxiv.org/abs/2510.09312) <a id="link30"></a>

**ArXiv ID:** 2510.09312

**Authors:** Zheng Zhao, Yeskendir Koishekenov, Xianjun Yang, Naila Murray, Nicola Cancedda

**Abstract:** Current Chain-of-Thought (CoT) verification methods predict reasoning correctness based on outputs (black-box) or activations (gray-box), but offer limited insight into why a computation fails. We introduce a white-box method: Circuit-based Reasoning Verification (CRV). We hypothesize that attribution graphs of correct CoT steps, viewed as execution traces of the model's latent reasoning circuits, possess distinct structural fingerprints from those of incorrect steps. By training a classifier on structural features of these graphs, we show that these traces contain a powerful signal of reasoning errors. Our white-box approach yields novel scientific insights unattainable by other methods. (1) We demonstrate that structural signatures of error are highly predictive, establishing the viability of verifying reasoning directly via its computational graph. (2) We find these signatures to be highly domain-specific, revealing that failures in different reasoning tasks manifest as distinct computational patterns. (3) We provide evidence that these signatures are not merely correlational; by using our analysis to guide targeted interventions on individual transcoder features, we successfully correct the model's faulty reasoning. Our work shows that, by scrutinizing a model's computational process, we can move from simple error detection to a deeper, causal understanding of LLM reasoning.

**Comment:** Representation Learning: white-box verification using structural features of attribution graphs to diagnose and intervene in latent reasoning circuits.

**Relevance:** 8
**Novelty:** 7

---

## 31. [Toward Mechanistic Explanation of Deductive Reasoning in Language Models](https://arxiv.org/abs/2510.09340) <a id="link31"></a>

**ArXiv ID:** 2510.09340

**Authors:** Davide Maltoni, Matteo Ferrara

**Abstract:** Recent large language models have demonstrated relevant capabilities in solving problems that require logical reasoning; however, the corresponding internal mechanisms remain largely unexplored. In this paper, we show that a small language model can solve a deductive reasoning task by learning the underlying rules (rather than operating as a statistical learner). A low-level explanation of its internal representations and computational circuits is then provided. Our findings reveal that induction heads play a central role in the implementation of the rule completion and rule chaining steps involved in the logical inference required by the task.

**Comment:** Representation Learning: mechanistic interpretability analyzing induction-head circuits that implement rule completion and chaining for deductive reasoning.

**Relevance:** 8
**Novelty:** 7

---

## 32. [Training Feature Attribution for Vision Models](https://arxiv.org/abs/2510.09135) <a id="link32"></a>

**ArXiv ID:** 2510.09135

**Authors:** Aziz Bacha, Thomas George

**Abstract:** Deep neural networks are often considered opaque systems, prompting the need for explainability methods to improve trust and accountability. Existing approaches typically attribute test-time predictions either to input features (e.g., pixels in an image) or to influential training examples. We argue that both perspectives should be studied jointly. This work explores *training feature attribution*, which links test predictions to specific regions of specific training images and thereby provides new insights into the inner workings of deep models. Our experiments on vision datasets show that training feature attribution yields fine-grained, test-specific explanations: it identifies harmful examples that drive misclassifications and reveals spurious correlations, such as patch-based shortcuts, that conventional attribution methods fail to expose.

**Comment:** Representation Learning: training feature attribution linking test predictions to specific regions of training images, revealing spurious correlations and influential training features.

**Relevance:** 8
**Novelty:** 7

---

## 33. [The Potential of Second-Order Optimization for LLMs: A Study with Full Gauss-Newton](https://arxiv.org/abs/2510.09378) <a id="link33"></a>

**ArXiv ID:** 2510.09378

**Authors:** Natalie Abreu, Nikhil Vyas, Sham Kakade, Depen Morwani

**Abstract:** Recent efforts to accelerate LLM pretraining have focused on computationally-efficient approximations that exploit second-order structure. This raises a key question for large-scale training: how much performance is forfeited by these approximations? To probe this question, we establish a practical upper bound on iteration complexity by applying full Gauss-Newton (GN) preconditioning to transformer models of up to 150M parameters. Our experiments show that full GN updates yield substantial gains over existing optimizers, achieving a 5.4x reduction in training iterations compared to strong baselines like SOAP and Muon. Furthermore, we find that a precise layerwise GN preconditioner, which ignores cross-layer information, nearly matches the performance of the full GN method. Collectively, our results suggest: (1) the GN approximation is highly effective for preconditioning, implying higher-order loss terms may not be critical for convergence speed; (2) the layerwise Hessian structure contains sufficient information to achieve most of these potential gains; and (3) a significant performance gap exists between current approximate methods and an idealized layerwise oracle.

**Comment:** Matches Training Efficiency/HPC: full and layerwise Gauss-Newton preconditioning for Transformers with iteration reductions and analysis of Hessian structure.

**Relevance:** 8
**Novelty:** 7

---

## 34. [Inverse-Free Wilson Loops for Transformers: A Practical Diagnostic for Invariance and Order Sensitivity](https://arxiv.org/abs/2510.08648) <a id="link34"></a>

**ArXiv ID:** 2510.08648

**Authors:** Edward Y. Chang, Ethan Y. Chang

**Abstract:** Large language models can change answers under harmless edits that matter in practice: RAG outputs flip when passages are reordered, fine-tuning erodes invariances learned at pretraining, debate or chain-of-thought prompts take path-dependent routes, and compiler fusion or reordering perturbs logits near decision boundaries. These failures violate intended invariances, break continuous integration, and force teams to trade safety for speed. The effects are small yet distributed across layers and positions, sensitive to context length and evaluation order, and costly to repair with retraining or formal verification. We present WILSON, a minimal post-hoc diagnostic suite that converts simple loop and reordering checks on internal representations into system signals. WILSON combines an inverse-free curvature map over positions and layers, computed with JVPs and Hutchinson probes, with activation-level commutators that flag reorder risk. Signals are cheap to compute, model-agnostic for standard Transformers, and exported as thresholds and CSV artifacts for orchestrators. This enables concrete actions: guard RAG against order effects, catch fine-tuning regressions, stabilize debate pathways and long multi-turn contexts, and gate fusions or reorders in deployment. In short, WILSON helps anticipate failures and approve safe optimizations so reliability and throughput can improve together without changing model architecture or training.

**Comment:** Matches ML Systems measurement + Representation Learning: post-hoc diagnostics for invariance/order sensitivity using JVP/Hutchinson probes; actionable reliability checks for Transformers.

**Relevance:** 8
**Novelty:** 7

---

## 35. [QuIRK: Quantum-Inspired Re-uploading KAN](https://arxiv.org/abs/2510.08650) <a id="link35"></a>

**ArXiv ID:** 2510.08650

**Authors:** Vinayak Sharma, Ashish Padhy, Vijay Jagdish Karanjkar, Sourav Behera, Lord Sen, Shyamapada Mukherjee, Aviral Shrivastava

**Abstract:** Kolmogorov-Arnold Networks or KANs have shown the ability to outperform classical Deep Neural Networks, while using far fewer trainable parameters for regression problems on scientific domains. Even more powerful has been their interpretability due to their structure being composed of univariate B-Spline functions. This enables us to derive closed-form equations from trained KANs for a wide range of problems. This paper introduces a quantum-inspired variant of the KAN based on Quantum Data Re-uploading~(DR) models. The Quantum-Inspired Re-uploading KAN or QuIRK model replaces B-Splines with single-qubit DR models as the univariate function approximator, allowing them to match or outperform traditional KANs while using even fewer parameters. This is especially apparent in the case of periodic functions. Additionally, since the model utilizes only single-qubit circuits, it remains classically tractable to simulate with straightforward GPU acceleration. Finally, we also demonstrate that QuIRK retains the interpretability advantages and the ability to produce closed-form solutions.

**Comment:** Matches Model Architecture (new KAN variant replacing B-splines with quantum-inspired data re-uploading units) and Efficiency (fewer parameters, interpretable univariate modules).

**Relevance:** 8
**Novelty:** 7

---

## 36. [FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching](https://arxiv.org/abs/2510.08669) <a id="link36"></a>

**ArXiv ID:** 2510.08669

**Authors:** Jiacheng Liu, Peiliang Cai, Qinming Zhou, Yuqi Lin, Deyang Kong, Benhao Huang, Yupei Pan, Haowen Xu, Chang Zou, Junshu Tang, Shikang Zheng, Linfeng Zhang

**Abstract:** The application of diffusion transformers is suffering from their significant inference costs. Recently, feature caching has been proposed to solve this problem by reusing features from previous timesteps, thereby skipping computation in future timesteps. However, previous feature caching assumes that features in adjacent timesteps are similar or continuous, which does not always hold in all settings. To investigate this, this paper begins with an analysis from the frequency domain, which reveal that different frequency bands in the features of diffusion models exhibit different dynamics across timesteps. Concretely, low-frequency components, which decide the structure of images, exhibit higher similarity but poor continuity. In contrast, the high-frequency bands, which decode the details of images, show significant continuity but poor similarity. These interesting observations motivate us to propose Frequency-aware Caching (FreqCa)   which directly reuses features of low-frequency components based on their similarity, while using a second-order Hermite interpolator to predict the volatile high-frequency ones based on its continuity.   Besides, we further propose to cache Cumulative Residual Feature (CRF) instead of the features in all the layers, which reduces the memory footprint of feature caching by 99%.   Extensive experiments on FLUX.1-dev, FLUX.1-Kontext-dev, Qwen-Image, and Qwen-Image-Edit demonstrate its effectiveness in both generation and editing. Codes are available in the supplementary materials and will be released on GitHub.

**Comment:** Matches Efficiency and ML Systems: frequency-aware feature caching with Hermite interpolation and CRF caching to cut memory by 99% and speed diffusion transformer inference.

**Relevance:** 8
**Novelty:** 7

---

## 37. [Geodesic Calculus on Latent Spaces](https://arxiv.org/abs/2510.09468) <a id="link37"></a>

**ArXiv ID:** 2510.09468

**Authors:** Florine Hartwig, Josua Sassen, Juliane Braunsmann, Martin Rumpf, Benedikt Wirth

**Abstract:** Latent manifolds of autoencoders provide low-dimensional representations of data, which can be studied from a geometric perspective. We propose to describe these latent manifolds as implicit submanifolds of some ambient latent space. Based on this, we develop tools for a discrete Riemannian calculus approximating classical geometric operators. These tools are robust against inaccuracies of the implicit representation often occurring in practical examples. To obtain a suitable implicit representation, we propose to learn an approximate projection onto the latent manifold by minimizing a denoising objective. This approach is independent of the underlying autoencoder and supports the use of different Riemannian geometries on the latent manifolds. The framework in particular enables the computation of geodesic paths connecting given end points and shooting geodesics via the Riemannian exponential maps on latent manifolds. We evaluate our approach on various autoencoders trained on synthetic and real data.

**Comment:** Representation Learning: geometric/Riemannian tools on autoencoder latent manifolds (geodesics, projections) that are architecture-agnostic and provide insights into latent structure.

**Relevance:** 8
**Novelty:** 7

---

## 38. [AB-PINNs: Adaptive-Basis Physics-Informed Neural Networks for Residual-Driven Domain Decomposition](https://arxiv.org/abs/2510.08924) <a id="link38"></a>

**ArXiv ID:** 2510.08924

**Authors:** Jonah Botvinick-Greenhouse, Wael H. Ali, Mouhacine Benosman, Saviz Mowlavi

**Abstract:** We introduce adaptive-basis physics-informed neural networks (AB-PINNs), a novel approach to domain decomposition for training PINNs in which existing subdomains dynamically adapt to the intrinsic features of the unknown solution. Drawing inspiration from classical mesh refinement techniques, we also modify the domain decomposition on-the-fly throughout training by introducing new subdomains in regions of high residual loss, thereby providing additional expressive power where the solution of the differential equation is challenging to represent. Our flexible approach to domain decomposition is well-suited for multiscale problems, as different subdomains can learn to capture different scales of the underlying solution. Moreover, the ability to introduce new subdomains during training helps prevent convergence to unwanted local minima and can reduce the need for extensive hyperparameter tuning compared to static domain decomposition approaches. Throughout, we present comprehensive numerical results which demonstrate the effectiveness of AB-PINNs at solving a variety of complex multiscale partial differential equations.

**Comment:** Model Architecture: introduces adaptive-basis PINNs with residual-driven, on-the-fly domain decomposition (dynamic subdomains), a conditional/dynamic training scheme aligned with architectural innovation criteria.

**Relevance:** 8
**Novelty:** 7

---

# Paper Selection Prompt

## System Prompt

> You are a helpful paper reading assistant whose job is to read daily posts from ArXiv and identify a few papers that your friend will enjoy reading.
> Your job is to carefully read the paper titles and abstracts below and find the ones that match the criteria below.

## User Prompt

> ## Instructions
> 
> Write the response in JSONL format with {ARXIVID, COMMENT, RELEVANCE, NOVELTY} on each line, one for each paper.
> 
> - ARXIVID: should be the ArXiv ID.
> - COMMENT: should identify whether there is a criteria that match the paper very closely. These matches should not be based on general terms like "language modeling" or "advancements" and should specifically refer to a criterion. No need to mention the non-matching criteria.
> - RELEVANCE: should be a score from 1-10.
> - NOVELTY: should be a score from 1-10.
> 
> ## Scoring Criteria
> 
> > The "Relevance" score measures how closely the paper aligns with the core topics of the prompt.
> > The "Novelty" score assesses the originality and impact of the paper.
> > They are two **ORTHONORMAL** axes and **SHOULD NOT** be confused with each other.
> 
> ### Relevance Scoring
> 
> - Relevance 9-10 (Completely Relevant)
>   - Focus: Fully aligned with core topics with no deviation, score the highest if contains relevant keywords in it.
>   - Examples: Papers focused on foundational methods or theoretical research, whose titles contain topic keywords like "MoE".
> 
> - Relevance 7-8 (Relevant)
>   - Focus: Retain a solid link to the main research area, though may touch on peripheral elements.
>   - Examples: Papers research on the fundamental part of MoE through a less critical aspect like its behavior in GNN.
> 
> - Relevance 5-6 (Borderline)
>   - Focus: Maintains a link to the core topic but also extends into at least one other domain/area beyond the primary focus.
>   - Examples: Work referencing MoE centered on reinforcement learning.
> 
> - Relevance 3-4 (Irrelevant)
>   - Focus: Largely outside our interests with no association to our topics.
>   - Examples: Application-focused papers like using MoE to solve a problem in the real world.
> 
> - Relevance 1-2 (Ignore)
>   - Focus: Purely unrelated to our topics. Completely a different domain.
>   - **Exception**: If the paper hints at a cutting-edge, radically new direction that could eventually transform the primary domain, consider a score of 9–10 despite initial appearances. (Usually a very rare concept that belongs to the fundamental research)
> 
> ### Novelty Scoring
> 
> - Novelty 9-10 (Breakthrough)
>   - Definition: Groundbreaking methods/theory introducing new directions or solving major challenges.
>   - Examples: Entirely new paradigm for foundational models; a novel theory transforming representation learning.
> 
> - Novelty 7-8 (Improvements)
>   - Definition: Substantial insights/enhancements, though not a full paradigm shift.
>   - Examples: Modifications on existing methods yielding significantly better results.
> 
> - Novelty 5-6 (Borderline)
>   - Definition: Incremental contributions with possible long-term benefits, not immediately transformative.
>   - Examples: Moderately novel extension to an existing architecture; refining current methods without fundamentally altering them.
> 
> - Novelty 3-4 (Tangential)
>   - Definition: Minor or domain-specific improvements with limited broader impact.
>   - Examples: Slight modifications to known methods with strange motivation; purely engineering jobs like a new benchmark/dataset.
> 
> - Novelty 1-2 (Low)
>   - Definition: Minimal originality, applying standard approaches without real innovation.
>   - Examples: Using an off-the-shelf model without adding new insights; purely application-driven studies like finetuning a pretrained model using existing methods.
> 
> ## Papers
> 
> [PAPER LIST HERE]
> 
> ## Relevant Topics
> 
> Use the following relevance criteria to focus on foundational research. Keep **relevant** papers and filter out **irrelevant** ones. Avoid purely **application-driven** work.
> 
> 1. Model Architecture
>    - Relevant: Mixture-of-Experts (MoE), Transformers, Conditional/Dynamic Networks, Autoencoders, analysis/innovations on existing architectures.
>    - Irrelevant: Merely using existing architectures for a certain task without insights into the structure themselves.
> 
> 2. Model Compression and Efficiency
>    - Relevant: Sparsity, pruning, quantization, low-rank approaches, cache, or other algorithmic/theoretical efficiency breakthroughs.
>    - Irrelevant: Straightforward applications of existing compression methods to new tasks.
> 
> 3. High Performance Computing
>    - Relevant: Algorithmic or systems-level innovations enabling training of large-scale models, distributed training techniques, memory optimization.
>    - Irrelevant: Incremental engineering improvements without novel algorithmic contributions.
> 
> 4. Representation Learning
>    - Relevant: Insights into how deep networks encode information, feature/dictionary learning, sparse/contrastive methods, training dynamics in neural networks.
>    - Irrelevant: Standard applications of known techniques lacking new theoretical or methodological contributions.
> 
> 5. ML Systems
>    - Goal: Keep ML-Systems work that provides fundamental, generalizable systems/algorithmic insights for training, inference, or deployment — not one-off application engineering.
>    - Relevant: 
>       - Distributed training algorithms and optimizations with theoretical/empirical scalability analysis (e.g., new sync/async protocols, communication compression with provable/empirical benefits).
>       - Memory / storage / I/O management improvements for very large models (hierarchical memory, recompute/checkpoint strategies, rematerialization optimizations).
>       - Communication & networking innovations (efficient AllReduce variants, topology-aware scheduling, bandwidth/latency–aware strategies).
>       - Compiler & automatic code-generation advances that enable operator fusion, memory scheduling, quantization-friendly IR passes.
>       - Heterogeneous acceleration & hardware–software co-design (CPU–GPU–NPU scheduling, kernel-level innovations with measurable gains).
>       - Inference-serving systems with strong evidence of low-latency / high-throughput tradeoffs, model-parallel + pipeline concurrency strategies, SLA-aware resource elasticity.
>       - Reproducible benchmarks & measurement methodologies that reveal system behavior and provide open tools/protocols.
>       - Algorithm–system co-design (e.g., systems built specifically for sparse/low-rank models, joint approximations that trade accuracy for system efficiency).
>       - Work with convincing quantitative/theoretical analysis, ablations, and results that generalize across topologies / hardware / model scales.
> 
>    -Irrelevant (Filter out):
>       - Papers that simply apply an existing framework/library to a dataset and report speedups without new system/algorithmic design.
>       - Purely application-focused engineering for a single domain (medical imaging, autonomous driving, etc.) without extracting generalizable system principles.
>       - Deployment notes or single-node config checklists without system-level analysis or broader lessons.
> 
>    - Practical filters / judging criteria:
>       - Does the paper include publicly reproducible code or benchmarks?
>       - Does it extract general principles or design patterns (not only case-specific optimizations)?
>       - Is there theoretical / complexity / communication-cost analysis or large-scale, multi-setting empirical validation?
>       - Does it address low-level kernels / communication / compilation / memory or propose a new system paradigm (e.g., new parallelism model, hierarchical storage design, combined algorithm/system optimization)?
> 
> **Keywords:**
> 
> - Relevant: Mixture of Experts (MoE), Representation Learning, Compression/Efficiency, Sparse/Sparsity, Pruning, Quantization, Low-rank, Foundation Model, etc.
> - Irrelevant: Reinforcement Learning, Transfer Learning, Federated Learning, Online Learning, Diffusion Models, etc.
> - Application: Image Segmentation, Medical Imaging, 3D Vision, Video Understanding, Information Retrieval, Summarization, Recommendation Systems, Machine Translation, Speech Recognition, Signal Processing, Spatial/Temporal Modeling, Time Series, Knowledge Graph, etc.